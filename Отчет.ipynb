{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какая получилась точность у модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность итоговой модели `OneVsRest Classifier with words n-grams` примерно `0.907`. Удивительно, что самая легкая, а вместе с тем и самая быстрая модель показала себя лучше всего на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какие есть способы ускорения/уменьшения модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшить модель можно путем изменения параметра `max_features` (количество признаков, которое`TfidfVectorizer` будет учить) или `ngram_range` (последовательности из скольких слов мы будем учитывать). Таким образом, мы можем уменьшить размер модели существенно, но не факт, что при этом мы не проиграем в качестве. Опять же, все это проверяется путем проб и ошибок.\n",
    "\n",
    "Также, для ускорения модели можно в качестве классификатора попробовать использовать решающие дерерья. Кроме всего прочего, решающие деревья еще и хороши для интерпретируемости работы модели в отличии от логистической регрессии. Однако при решении нашей задачи использование решающих деревье не улучшило качество модели, поэтому используется логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как выбрать баланс между качеством и скоростью?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс между качеством и скоростью можно выбрать, например, следующим способом. Можно сначала построить несколько легких моделей с хороших качеством, а затем, например, скомбинировать решения, чтобы улучшить итоговые предсказания (`ensemble models`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что лучше — тяжелая модель и потом ее оптимизировать или сразу легкая?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала лучше всего построить легкую модель, чтобы был понятный и уверенный бейзлайн. Дальше уже можно пробовать усложнять модель и проверять ее на предмет улучшения качества. Обычно увеличение модели в несколько раз влечёт всего 10-20 относительных процентов качества. Если при решении поставленной задачи можно на это пойти - тогда это стоит делать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Опишите ваш подход. Чем он лучше других возможных подходов? Какие у него могут быть недостатки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала из текстов удаляются все не алфавитные знаки (вроде знаков препинания и всех прочих символов), затем все слова в текстах подвергаются стеммингу и на основе TF-IDF, учитывая n-граммы слов, конструируются признаки для обучения модели. Далее мы разбиваем наш датасет на `n_labels` датасетов и для каждого отдельно учим бинарную классификацию (в нашем случае логистическую регрессию). \n",
    "\n",
    "Этот метод хорош тем, что он способен улавливать достаточно сложные закономерности в данных за счет учитывания при конструировании признаков не только отдельных слов, но также и словосочетаний, состоящих из 2 слов (например, \"нравится\" и \"не нравится\" имеют координально противоположные значения, но если бы мы не учитывали словосочетания наша модель этого бы просто напросто не заметила). Тем не менее наша модель никак не учитывает корреляцию между итоговыми лейблами (однако при применении к этой модели `Classifiers chains` качество не учучшилось).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что можно сделать, чтобы улучшить классификатор?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой ответ на данный вопрос - настройка параметров модели. Так же, как уже было сказано выше, можно скомбинировать решения нескольких классификатор. \n",
    "\n",
    "Как было показано в работе, LSTM сеть не улучшила качество предсказаний. Но если все-таки хочется еще улучшить качество и построить глубокую сеть, то лучше воспользоваться одномерными свертками (`1D Convolutions`). Их преимущество над LSTM слоями заключается в том, что они работают значительно быстрее и в данной задаче это может быть нам на руку."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
